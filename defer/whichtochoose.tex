% defer/whichtochoose.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Which to Choose?}
\label{sec:defer:Which to Choose?}
%
\epigraph{Choose always the way that seems the best, however rough it
	  may be; custom will soon render it easy and agreeable.}
	  {\emph{Pythagoras}}

This section provides a high-level overview and then a more detailed view
of the differences between the deferred-processing techniques presented
in this chapter.
This discussion assumes a linked data structure that is large enough
that readers do not hold references from one traversal to another,
and where elements might be added to and removed from the structure
at any location and at any time.
This discussion should help you to make an informed choice between
these techniques.

\subsection{Which to Choose? (Overview)}
\label{sec:defer:Which to Choose? (Overview)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.0in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Readers
		& Slow and unscalable
			& Fast and scalable
				& Fast and scalable
					& Fast and scalable \\
	Number of Protected Objects
		& Scalable
			& Unscalable
				& No protection
					& Scalable \\
	Duration of Protection
		& Can be long
			& Can be long
				& No protection
					& User must bound duration \\
	Need for Traversal Retries
		& If race with object deletion
			& If race with object deletion
				& If race with any update
					& Never \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose? (Overview)}
\label{tab:defer:Which Deferred Technique to Choose? (Overview)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Overview)}
shows a few high-level properties that distinguish the deferred-reclamation
techniques from one another.

The ``Readers'' row summarizes the results presented in
Figure~\ref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR},
which shows that all but reference counting are enjoy reasonably
fast and scalable readers.

The ``Number of Protected Objects'' row evaluates each technique's need
for external storage with which to record reader protection.
RCU relies on quiescent states, and thus needs no storage to represent
readers, whether within or outside of the object.
Reference counting can use a single integer within each object in the
structure, and no additional storage is required.
Hazard pointers requires external-to-object pointers be provisioned,
and that there be sufficient pointers to handle the maximum number of
objects that a given CPU or thread might need to reference simultaneously.
Of course, sequence locks provides no pointer-traversal protection,
which is why it is normally used on static data.

\QuickQuiz{}
	Why can't users dynamically allocate the hazard pointers as they
	are needed?
\QuickQuizAnswer{
	They can, but at the expense of additional reader-traversal
	overhead and, in some environments, the need to handle
	memory-allocation failure.
} \QuickQuizEnd

The ``Duration of Protection'' describes constraints (if any) on how
long a period of time a user may protect a given object.
Reference counting and hazard pointers can both protect objects for
extended time periods with no untoward side effects, but
maintaining an RCU reference to even one object prevents all other RCU
from being freed.
RCU readers must therefore be relatively short in order to avoid running
the system out of memory.
Again, sequence locks provides no pointer-traversal protection,
which is why it is normally used on static data.

The ``Need for Traversal Retries'' row tells whether a new reference to
a given object may be acquired unconditionally, as it can with RCU, or
whether the reference acquisition can fail, resulting in a retry
operation, which is the case for reference counting, hazard pointers,
and sequence locks.
In the case of reference counting and hazard pointers, retries are only
required if an attempt to acquire a reference to a given object while
that object is in the processof being deleted, a topic covered in more
detail in the next section.
Sequence locking must of course retry its critical section should it
run concurrently with any update.

\QuickQuiz{}
	But don't Linux-kernel \co{kref} reference counters allow
	guaranteed unconditional reference acquisition?
\QuickQuizAnswer{
	Yes they do, but the guarantee only applies unconditionally
	in cases where a reference is already held.
	With this in mind, please review the paragraph at the beginning of
	Section~\ref{sec:defer:Which to Choose?}, especially the part
	saying ``large enough that readers do not hold references from
	one traversal to another''.
} \QuickQuizEnd

Of course, different rows will have different levels of importance in
different situations.
For example, if your current code is having read-side scalability problems
with hazard pointers, then it does not matter that hazard pointers can require
retrying reference acquisition because your current code already handles
this.
Similarly, if real-time considerations already limit the duration of reader
traversals, then it does not matter that RCU has duration-limit requirements
because your code already meets them.
Nevertheless, this table should be of great help when choosing between
these techniques.
But those wishing more detail should continue on to the next section.

\subsection{Which to Choose? (Details)}
\label{sec:defer:Which to Choose? (Details)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.2in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Existence Guarantees
		& Complex
			& Yes
				& No
					& Yes \\
	Updates and Readers Progress Concurrently
		& Yes
			& Yes
				& No
					& Yes \\
	Contention Among Readers
		& High
			& None
				& None
					& None \\
	Reader Per\-/Critical\-/Section Overhead
		& N/A
			& N/A
				& Two \tco{smp_mb()}
					& Ranges from none to two
					  \tco{smp_mb()} \\
	Reader Per-Object Traversal Overhead
		& Read-modify-write atomic operations, memory\-/barrier
		  instructions, and cache misses
			& \tco{smp_mb()}
				& None, but unsafe
					& None (volatile accesses) \\
	Reader Forward Progress Guarantee
		& Lock free
			& Lock free
				& Blocking
					& Bounded wait free \\
	Reader Reference Acquisition
		& Can fail (conditional)
			& Can fail (conditional)
				& Unsafe
					& Cannot fail (unconditional) \\
	Memory Footprint
		& Bounded
			& Bounded
				& Bounded
					& Unbounded \\
	Reclamation Forward Progress
		& Lock free
			& Lock free
				& N/A
					& Blocking \\
	Automatic Reclamation
		& Yes
			& No
				& N/A
					& No \\
	Lines of Code
		& 94
			& 79
				& 79
					& 73 \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose?  (Details)}
\label{tab:defer:Which Deferred Technique to Choose?  (Details)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Details)}
provides more-detailed rules of thumb that can help you choose among the
four deferred-processing techniques presented in this chapter.

As shown in the ``Existence Guarantee'' row,
if you need existence guarantees for linked
data elements, you must use reference counting, hazard pointers, or RCU.
Sequence locks do not provide existence guarantees, instead providing
detection of updates, retrying any read-side critical sections
that do encounter an update.

Of course, as shown in the ``Updates and Readers Progress Concurrently''
row, this detection of updates implies
that sequence locking does not permit updaters and readers to make forward
progress concurrently.
After all, preventing such forward progress is the whole point of using
sequence locking in the first place!
This situation points the way to using sequence locking in conjunction
with reference counting, hazard pointers, or RCU in order to provide
both existence guarantees and update detection.
In fact, the Linux kernel combines RCU and sequence locking in
this manner during pathname lookup.

The ``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
and ``Reader Per-Object Traversal Overhead'' rows give a rough sense of
the read-side overhead of these techniques.
The overhead of reference counting can be quite large, with
contention among readers along with a fully ordered read-modify-write
atomic operation required for each and every object traversed.
Hazard pointers incur the overhead of a memory barrier for each data element
traversed, and sequence locks incur the overhead of a pair of memory barriers
for each attempt to execute the critical section.
The overhead of RCU implementations vary from nothing to that of a pair of
memory barriers for each read-side critical section, thus providing RCU
with the best performance, particularly for read-side critical sections
that traverse many data elements.
Of course, the read-side overhead of all deferred-processing variants can
be reduced by batching, so that each read-side operation covers more data.

\QuickQuiz{}
	But didn't the answer to one of the quick quizzes in
	Section~\ref{sec:defer:Hazard Pointers}
	say that pairwise asymmetric barriers could eliminate the
	read-side \co{smp_mb()} from hazard pointers?
\QuickQuizAnswer{
	Yes, it did.
	However, doing this could be argued to change hazard pointers's
	``Reclamation Forward Progress'' row (discussed later) from
	lock-free to blocking because a CPU spinning with interrupts
	disabled in the kernel would prevent the update-side portion of
	the asymmetric barrier from completing.
	In the Linux kernel, such blocking could in theory be prevented
	by building the kernel with \co{CONFIG_NO_HZ_FULL}, designating
	the relevant CPUs as \co{nohz_full} at boot time, ensuring that
	only one thread was ever runnable on a given CPU at a given
	time, and avoiding ever calling into the kernel.
	Alternatively, you could ensure that the kernel was free of any
	bugs that might cause CPUs to spin with interrupts disabled.

	Given that CPUs spinning in the Linux kernel with interrupts
	disabled seems to be rather rare, one might counter-argue that
	asymmetric-barrier hazard-pointer updates are non-blocking
	in practice, if not in theory.
} \QuickQuizEnd

The ``Reader Forward Progress Guarantee'' row shows that only RCU
has a bounded wait-free forward-progress guarantee, which means that
it can carry out a finite traversal by executing a bounded number of
instructions.

The ``Reader Reference Acquisition'' rows indicates that only RCU is
capable of unconditionally acquiring references.
The entry for sequence locks is ``Unsafe'' because, again, sequence locks
detect updates rather than acquiring references.
Reference counting and hazard pointers both require that traversals be
restarted from the beginning if a given acquisition fails.
To see this, consider a linked list containing objects~A, B, C, and~D,
in that order, and the following series of events:

\begin{enumerate}
\item	A reader acquires a reference to object~B.
\item	An updater removes~object B, but refrains from freeing it because
	the reader holds a reference.
	The list now contains objects~A, C, and~D, and
	object~B's \co{->next} pointer is set to \co{HAZPTR_POISON}.
\item	The updater removes object~C, so that the list now contains
	objects~A and~D.
	Because there is no reference to object~C, it is immediately freed.
\item	The reader tries to advance to the successor of the object
	following the now-removed object~B, but the poisoned
	\co{->next} pointer prevents this.
	Which is a good thing, because object~B's \co{->next} pointer
	would otherwise point to the freelist.
\item	The reader must therefore restart its traversal from the head
	of the list.
\end{enumerate}

Thus, when failing to acquire a reference, a hazard-pointer or
reference-counter traversal must restart that traversal from the
beginning.
In the case of nested linked data structures, for example, a
tree containing linked lists, the traversal must be restarted from
the outermost data structure.
This situation gives RCU a significant ease-of-use advantage.

However, RCU's ease-of-use advantage does not come
for free, as can be seen in the ``Memory Footprint'' row.
RCU's support of unconditional reference acquisition means that
it must avoid freeing any object reachable by a given
RCU reader until that reader completes.
RCU therefore has an unbounded memory footprint, at least unless updates
are throttled.
In contrast, reference counting and hazard pointers need to  retain only
those data elements actually referenced by concurrent readers.

This tension between memory footprint and acquisition
failures is sometimes resolved within the Linux kernel by combining use
of RCU and reference counters.
RCU is used for short-lived references, which means that RCU read-side
critical sections can be short.
These short RCU read-side critical sections in turn mean that the corresponding
RCU grace periods can also be short, which limits the memory footprint.
For the few data elements that need longer-lived references, reference
counting is used.
This means that the complexity of reference-acquisition failure only
needs to be dealt with for those few data elements:  The bulk of
the reference acquisitions are unconditional, courtesy of RCU.
See Section~\ref{sec:together:Refurbish Reference Counting}
for more information on combining reference counting with other
synchronization mechanisms.

The ``Reclamation Forward Progress'' row shows that hazard pointers
can provide non-blocking updates~\cite{MagedMichael04a,HerlihyLM02}.
Reference counting might or might not, depending on the implementation.
However, sequence locking cannot provide non-blocking updates, courtesy
of its update-side lock.
RCU updaters must wait on readers, which also rules out fully non-blocking
updates.
However, there are situations in which the only blocking operation is
a wait to free memory, which results in an situation that, for many
purposes, is as good as non-blocking~\cite{MathieuDesnoyers2012URCU}.

As shown in the ``Automatic Reclamation'' row, only reference
counting can automate freeing of memory, and even then only
for non-cyclic data structures.

Finally, the ``Lines of Code'' row shows the size of the Pre-BSD
Routing Table implementations, giving a rough idea of relative ease of use.
That said, it is important to note that the reference-counting and
sequence-locking implementations are buggy, and that a correct
reference-counting implementation is considerably
more complex~\cite{Valois95a,MagedMichael95a}.
For its part, a correct sequence-locking implementation requires
the addition of some other synchronization mechanism, for example,
hazard pointers or RCU, so that sequence locking detects concurrent
updates and the other mechanism provides safe reference acquisition.

As more experience is gained using these techniques, both separately
and in combination, the rules of thumb laid out in this section will
need to be refined.
However, this section does reflect the current state of the art.
